{
	"name": "Drug Discovery prediction using LightGBM Regressor",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "37af8f58-9428-46d9-b318-ce548996c99d"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			}
		},
		"cells": [
			{
				"cell_type": "markdown",
				"source": [
					"# Quantile Regression for Drug Discovery with LightGBM Regressor"
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Introduction of LightGBM\n",
					"[LightGBM](https://github.com/Microsoft/LightGBM) is an open-source, distributed, high-performance gradient boosting framework with following advantages: \n",
					"-   Composability: LightGBM models can be incorporated into existing\n",
					"    SparkML Pipelines, and used for batch, streaming, and serving\n",
					"    workloads.\n",
					"-   Performance: LightGBM on Spark is 10-30% faster than SparkML on\n",
					"    the Higgs dataset, and achieves a 15% increase in AUC.  [Parallel\n",
					"    experiments](https://github.com/Microsoft/LightGBM/blob/master/docs/Experiments.rst#parallel-experiment)\n",
					"    have verified that LightGBM can achieve a linear speed-up by using\n",
					"    multiple machines for training in specific settings.\n",
					"-   Functionality: LightGBM offers a wide array of [tunable\n",
					"    parameters](https://github.com/Microsoft/LightGBM/blob/master/docs/Parameters.rst),\n",
					"    that one can use to customize their decision tree system. LightGBM on\n",
					"    Spark also supports new types of problems such as quantile regression.\n",
					"-   Cross platformï¼šLightGBM on Spark is available on Spark (Scala) and PySpark (Python)."
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"<img src=\"https://mmlspark.blob.core.windows.net/graphics/Documentation/drug.png\" width=\"800\" style=\"float: center;\"/>\n",
					"\n",
					"In this example, we use LightGBM quantile regressor on the Triazines dataset."
				]
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Read dataset"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"triazines = spark.read.format(\"libsvm\").load(\"wasbs://publicwasb@mmlspark.blob.core.windows.net/triazines.scale.svmlight\")"
				],
				"execution_count": 1
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Exploratory data"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# print some basic info\n",
					"print(\"records read: \" + str(triazines.count()))\n",
					"print(\"Schema: \")\n",
					"triazines.printSchema()\n",
					"triazines.limit(10).toPandas()"
				],
				"execution_count": 2
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Generation of testing and training data sets\r\n",
					"\r\n",
					"Simple split, 85% for training and 15% for testing the model. Playing with this ratio may result in different models."
				]
			},
			{
				"cell_type": "code",
				"source": [
					"train, test = triazines.randomSplit([0.85, 0.15], seed=1)"
				],
				"execution_count": 3
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Train the model\r\n",
					"Train the quantile regressor on the training data."
				]
			},
			{
				"cell_type": "code",
				"source": [
					"from mmlspark.lightgbm import LightGBMRegressor\n",
					"model = LightGBMRegressor(objective='quantile',\n",
					"                          alpha=0.2,\n",
					"                          learningRate=0.3,\n",
					"                          numLeaves=31).fit(train)"
				],
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": true
				},
				"source": [
					"# Save and load LightGBM to a file using the LightGBM native representation\r\n",
					"\r\n",
					"from mmlspark.lightgbm import LightGBMRegressionModel\r\n",
					"model.saveNativeModel(\"/mymodel\")\r\n",
					"model = LightGBMRegressionModel.loadNativeModelFromFile(\"/mymodel\")"
				],
				"execution_count": 5
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": true
				},
				"source": [
					"# View the feature importances of the trained model\r\n",
					"\r\n",
					"print(model.getFeatureImportances())"
				],
				"execution_count": 6
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Model performance evaluation\r\n",
					"\r\n",
					"After training the model, we evaluate the performance of the model using the test set."
				]
			},
			{
				"cell_type": "code",
				"source": [
					"scoredData = model.transform(test)\n",
					"scoredData.limit(10).toPandas()"
				],
				"execution_count": 7
			},
			{
				"cell_type": "code",
				"source": [
					"# Compute metrics using ComputeModelStatistics\n",
					"\n",
					"from mmlspark.train import ComputeModelStatistics\n",
					"metrics = ComputeModelStatistics(evaluationMetric='regression',\n",
					"                                 labelCol='label',\n",
					"                                 scoresCol='prediction') \\\n",
					"            .transform(scoredData)\n",
					"metrics.toPandas()"
				],
				"execution_count": 8
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Clean up resources\r\n",
					"To ensure the Spark instance is shut down, end any connected sessions(notebooks). The pool shuts down when the **idle time** specified in the Apache Spark pool is reached. You can also select **stop session** from the status bar at the upper right of the notebook.\r\n",
					"\r\n",
					"![stopsession](https://adsnotebookrelease.blob.core.windows.net/adsnotebookrelease/adsnotebook/image/stopsession.png)"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Next steps\r\n",
					"\r\n",
					"* [Check out Synapse sample notebooks](https://github.com/Azure-Samples/Synapse/tree/main/MachineLearning) \r\n",
					"* [MMLSpark GitHub Repo](https://github.com/Azure/mmlspark)"
				]
			}
		]
	}
}